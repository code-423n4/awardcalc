This protocol details what processing needs to be applied to the raw aggregated contest finding results in order to  produce the final human readable [Audit Reports](https://code423n4.com/reports) shared with the public on the C4 website.

TO ADD:
a screen and link that gives a good before after comparison

## Report Drafting Protocol

## Eric's summary of process
### * -(1) Run Report:
    * In awardCalc repo, create and configure contest-config.json file then run "npm run reportâ€
    * to generate "draft reportâ€ markdown document (via npm run report) > this is your raw content for the final "Findings Report"
    * (â“ is that report.ts script... looks like the draft report is run with nom run report)
### * -(2) Edit sponsor-draft-report:
    * â“Save content generated in previous step as awardcalc/past_contests/sponorName-draft/report.md
    * â­• Add all the things we talked about here from Y 210610 ğŸ“ "Contest Reports: You Can Too!" w/Eric (hyperlink headersâ€¦)
###  * -(3) Move final product to C4 website repo _reports folder :
    *  Copy completed sponsorName-draft-report.md to code423n4.com/_reports renamed as YYYY-MM-sponsor.md
 ### * -(4) commit, push and submit pull request that adds report:
    * Identify reviewers in PR
###  * -(5) Merge after review and finals edits:
    * _reports folder in code423n4.com repo  (code-423n4/code423n4.com/tree/main/_reports)

## From Eric walkthrough
â€“ First 60 lines are not included and must be manually copy pasted from other reports (change contest specific items) >edit wardens participated (â”where to get) > Judge > Editor >vulnerability count  > Link to contest repo...
â€“ * Linked header
* Wardens comments (take a bit of copy editingâ€¦) take out judgement
* Sponsor comment on issue
* Take out log header
* â“ difference between acknowledge (not going to action) and confirmed (sponsor understands, agrees and maybe provides feedback), disputed (sponsor disagrees)
* Functions and variable names get â€œbacktickâ€ ` to markdown formatted to look like code
